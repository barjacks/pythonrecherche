{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NTLK]('http://www.nltk.org/') Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding how NTLK works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = \"\"\"At eight o'clock on Thursday morning\n",
    "... Arthur didn't feel very good.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'eight',\n",
       " \"o'clock\",\n",
       " 'on',\n",
       " 'Thursday',\n",
       " 'morning',\n",
       " 'Arthur',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'feel',\n",
       " 'very',\n",
       " 'good',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('At', 'IN'),\n",
       " ('eight', 'CD'),\n",
       " (\"o'clock\", 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('Thursday', 'NNP'),\n",
       " ('morning', 'NN'),\n",
       " ('Arthur', 'NNP'),\n",
       " ('did', 'VBD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('feel', 'VB'),\n",
       " ('very', 'RB'),\n",
       " ('good', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at this list of tags (https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So lets try to use this on out Daphne data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('allPostText_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 11 columns):\n",
      "Unnamed: 0      100 non-null int64\n",
      "Unnamed: 0.1    100 non-null int64\n",
      "Date_1          100 non-null int64\n",
      "Date_2          100 non-null int64\n",
      "Date_3          100 non-null object\n",
      "ID_page         100 non-null int64\n",
      "ID_post         100 non-null int64\n",
      "Link            100 non-null object\n",
      "Title           100 non-null object\n",
      "Txt             89 non-null object\n",
      "Text            100 non-null object\n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 8.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec(name):\n",
    "    tokens = nltk.word_tokenize(name)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(«, VB), (back, RB), (to, TO), (home, NN), (Y...\n",
       "1    [(«, VB), (back, RB), (to, TO), (home, NN), (E...\n",
       "2    [(«, VB), (back, RB), (to, TO), (home, NN), (I...\n",
       "3    [(«, VB), (back, RB), (to, TO), (home, NN), (T...\n",
       "4    [(«, VB), (back, RB), (to, TO), (home, NN), (“...\n",
       "5    [(«, VB), (back, RB), (to, TO), (home, NN), («...\n",
       "6    [(«, VB), (back, RB), (to, TO), (home, NN), (I...\n",
       "7    [(«, VB), (back, RB), (to, TO), (home, NN), (T...\n",
       "8    [(«, VB), (back, RB), (to, TO), (home, NN), («...\n",
       "9    [(«, VB), (back, RB), (to, TO), (home, NN), (D...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].apply(vec).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Tags'] = df['Text'].apply(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only consider the ones, with NNP as second item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token(tags):\n",
    "    mini_list = []\n",
    "    for elem in tags:\n",
    "        if elem[1] == 'NNP':\n",
    "            mini_list.append(elem[0])\n",
    "    return mini_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['People list'] = df['Tags'].apply(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   []\n",
       "1    [Kurz, Austria’s, People’s, Party, OVP, Freedo...\n",
       "2    [Naxxar, Labour, Party, Prime, Minister’s, Sun...\n",
       "3    [Nationalist, Party, Nationalist, Party, Malta...\n",
       "4                                              [“I, «]\n",
       "5                                                  [«]\n",
       "6                                                   []\n",
       "7    [Toni, Bezzina, Nationalist, Party’s, MP, Robe...\n",
       "8                                                  [«]\n",
       "9    [David, Agius, Nationalist, Party’s, Edwin, Va...\n",
       "Name: People list, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['People list'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Not great, so lets look around for a better solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This looks promising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sudo python -m nltk.downloader all``` if you have problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Code stolen from Stackoverflow](https://stackoverflow.com/questions/31836058/nltk-named-entity-recognition-to-a-python-list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON, Sebastian Kurz\n",
      "ORGANIZATION, OVP\n",
      "ORGANIZATION, Freedom Party\n",
      "ORGANIZATION, FPÖ\n",
      "ORGANIZATION, Social Democrats\n",
      "ORGANIZATION, People’s Party\n",
      "ORGANIZATION, People’s Party\n",
      "GPE, Sebastian\n",
      "PERSON, Kurz\n",
      "PERSON, Christian Kern\n",
      "ORGANIZATION, Social Democrats\n",
      "PERSON, Kurz\n",
      "GSP, Austria\n"
     ]
    }
   ],
   "source": [
    "for sent in nltk.sent_tokenize(df['Text'][1]):\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "        if hasattr(chunk, 'label'):\n",
    "            print(chunk.label()+',', ' '.join(c[0] for c in chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def peopled(elem):\n",
    "    mini_list = []\n",
    "    for sent in nltk.sent_tokenize(elem):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "            if hasattr(chunk, 'label'):\n",
    "                p = chunk.label(), ' '.join(c[0] for c in chunk)\n",
    "                mini_list.append(p)\n",
    "    return mini_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['people'] = df['Text'].apply(peopled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only getting the peolple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(df['people'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [x for x in lst if x !=[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in lst for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_list = []\n",
    "for name in flat_list:\n",
    "    if name[0] == 'PERSON':\n",
    "        name_list.append(name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delia                   41\n",
       "Adrian Delia            31\n",
       "Malta                   14\n",
       "Jean Pierre Debono      14\n",
       "Debono                  12\n",
       "Muscat                  10\n",
       "Mrs Delia                8\n",
       "Agius                    7\n",
       "Rebecca Dimech           7\n",
       "Joseph Muscat            7\n",
       "David Agius              6\n",
       "Anton Rea Cutajar        5\n",
       "David                    5\n",
       "Frank Portelli           5\n",
       "Adrian Delia’s           5\n",
       "Clyde Puli               4\n",
       "Clyde                    4\n",
       "Kristy Debono            4\n",
       "Bundy                    4\n",
       "Cutajar                  4\n",
       "Robert Arrigo            4\n",
       "Eddie Fenech Adami       3\n",
       "Keith Schembri           3\n",
       "Keith                    3\n",
       "Kristy                   3\n",
       "Borg Olivier             3\n",
       "Edwin Vassallo           3\n",
       "Andre Falzon             3\n",
       "Fenech Adami             2\n",
       "Kurt Farrugia            2\n",
       "                        ..\n",
       "Hubert Zammit            1\n",
       "Bad                      1\n",
       "Pasta Rummo              1\n",
       "Toni Bezzina             1\n",
       "Kevin Cassar             1\n",
       "Censu L-Iswed            1\n",
       "Rudyard                  1\n",
       "Xaraban                  1\n",
       "Mad                      1\n",
       "Puli                     1\n",
       "Alexander                1\n",
       "Borg                     1\n",
       "Malta here.The Times     1\n",
       "Hang                     1\n",
       "Mandalay                 1\n",
       "Farrugia                 1\n",
       "Censu                    1\n",
       "Leonardo Fasoli          1\n",
       "Manwel Dimech Street     1\n",
       "Gozo                     1\n",
       "Opposition               1\n",
       "Chris Said               1\n",
       "Rebecca                  1\n",
       "Pierre                   1\n",
       "Joseph Muscat.”          1\n",
       "Joe                      1\n",
       "Botox                    1\n",
       "Beppe Fenech Adami       1\n",
       "Gonzi                    1\n",
       "Maze Pictures            1\n",
       "Name: 0, Length: 171, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(name_list)[0].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
